{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5G7ugMJtOMWw"
   },
   "source": [
    "<h1> <font color='red'> DO read all the comments in the python code and conents in the markdow cells</font> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNLBT5GUbQUN"
   },
   "source": [
    "<pre><font size=4><b>\n",
    "You can do this assignment in google colab itself. we have provided a notebook to used tensorboard in google colab itself.</b></font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjzTYtr1OMW3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#enabled to get instant output. if you don't need, you can use session concept which was dicussed in lecture videos. \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0WP3DUvOMW_"
   },
   "source": [
    "## 1.1 Addition\n",
    "<pre> It is similar to numpy addition.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcKl2W9qOMXC",
    "outputId": "5ea26b1e-158e-493b-8a3c-8882931065fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.6681893 , 0.17386007],\n",
       "       [0.14307678, 0.17582059]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(2,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COUVYv5BOMXO",
    "outputId": "2e4e19dd-fdab-458e-aa53-f6029a50430e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.3085009 , 0.87729096],\n",
       "       [0.6298034 , 0.05569398]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(2,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7I1KMCgiOMXV"
   },
   "outputs": [],
   "source": [
    "add = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksQu6lT6OMXa",
    "outputId": "9fdcd302-7fb3-494f-94b3-2b28ac701c13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=16, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.9766902 , 1.051151  ],\n",
       "       [0.7728802 , 0.23151457]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPxWE4stOMXe"
   },
   "source": [
    "<pre>Broadcasting works similar to numpy.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKaICOghOMXg"
   },
   "outputs": [],
   "source": [
    "c = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pINN69LOMXn"
   },
   "outputs": [],
   "source": [
    "add_2 = a + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIaJTqAwOMXr",
    "outputId": "c510312e-78e7-45d0-d40d-52780d62b18c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=19, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.6681893, 2.17386  ],\n",
       "       [2.143077 , 2.1758206]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rOJ8iYoOMXw"
   },
   "source": [
    "## 1.2 Subtraction\n",
    "<pre> It is similar to numpy Subtraction.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8o22IU7OMXy",
    "outputId": "9bfb179f-8fad-4ef5-cdc6-7b918e37ac6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=27, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.96623254, 0.2679931 ],\n",
       "       [0.1549604 , 0.0160538 ]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(2,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUEmz0MKOMX5",
    "outputId": "87012331-692b-4218-d7ff-33b2d97c0a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.6590533 , 0.7576201 ],\n",
       "       [0.06813145, 0.25504053]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(2,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlGlc6CZOMX8"
   },
   "outputs": [],
   "source": [
    "sub = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mEst3O84OMYB",
    "outputId": "36456888-3567-4e6e-df04-9cc606fd3b63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=37, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 0.3071792 , -0.489627  ],\n",
       "       [ 0.08682895, -0.23898673]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fjRvsmIOMYG"
   },
   "source": [
    "## 1.3 Multiplication\n",
    "<pre>\n",
    "- For two dimensional matrices, you can multiply (m*n) and (n*p) and get (m*p)\n",
    "- for 3 dim matrices, you can multiply (b * n * p)  and (b * p * m)  and get (b * n * m). ( for any dim, you have to maintain last 2 dim as two dim multiplication and first n-2 dim has to be same. you will get better idea if you gothrough    all the operation which we have written below.)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwTNd9c9OMYI",
    "outputId": "b7b2476c-db99-405d-e6f9-b09d9680adc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=45, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.29050803, 0.30713832],\n",
       "       [0.08211851, 0.08445466],\n",
       "       [0.5099721 , 0.7720585 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Z3SOY-9OMYL",
    "outputId": "3a2c4ef2-bf07-44d3-dda3-0d51c21aee48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.8981422 , 0.9577384 , 0.16385424, 0.92287314],\n",
       "       [0.67601347, 0.9042326 , 0.07179487, 0.06531787]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(2,4))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PKZKq6COMYP",
    "outputId": "858e7e21-e17e-486d-8089-d56ac69f356f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=55, shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0.46854717, 0.5559552 , 0.06965193, 0.28816366],\n",
       "       [0.13084659, 0.15501471, 0.01951888, 0.08130136],\n",
       "       [0.9799494 , 1.1865404 , 0.13899094, 0.52106875]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a, b)# (3*2)@(2*4) = (3*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYtPMQCFOMYV"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qx21Dbw3OMYY"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKVwmcKROMYY",
    "outputId": "91d8271f-1792-4f19-8997-785831f47032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=63, shape=(3, 2, 4), dtype=float32, numpy=\n",
       "array([[[0.82100654, 0.7068696 , 0.6719074 , 0.30737042],\n",
       "        [0.12511992, 0.83287346, 0.30451667, 0.12773764]],\n",
       "\n",
       "       [[0.5733458 , 0.4111066 , 0.02079976, 0.8711932 ],\n",
       "        [0.9080281 , 0.8700478 , 0.02679706, 0.7849245 ]],\n",
       "\n",
       "       [[0.32611918, 0.07710814, 0.10108078, 0.00236273],\n",
       "        [0.92903423, 0.8469634 , 0.98838115, 0.33158827]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzkP827ROMYd",
    "outputId": "f4982e2e-0f8b-4a2a-f552-b5bc5797e5e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=71, shape=(3, 4, 3), dtype=float32, numpy=\n",
       "array([[[0.9548464 , 0.6803129 , 0.5736983 ],\n",
       "        [0.4882847 , 0.17908418, 0.23330784],\n",
       "        [0.02242708, 0.6318985 , 0.24775839],\n",
       "        [0.88342786, 0.32215428, 0.10884869]],\n",
       "\n",
       "       [[0.81257725, 0.6698991 , 0.897701  ],\n",
       "        [0.34282756, 0.54817235, 0.6707219 ],\n",
       "        [0.572088  , 0.3199314 , 0.06134105],\n",
       "        [0.7365929 , 0.12451577, 0.78196275]],\n",
       "\n",
       "       [[0.5694362 , 0.08203363, 0.39916778],\n",
       "        [0.744702  , 0.71693754, 0.41426373],\n",
       "        [0.4045236 , 0.14003599, 0.3162644 ],\n",
       "        [0.64604545, 0.96056724, 0.04877901]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(3,4,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5czLohlFOMYg",
    "outputId": "c786fe34-52f4-471d-fe02-dff13776af91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=73, shape=(3, 2, 3), dtype=float32, numpy=\n",
       "array([[[1.4156972 , 1.2087286 , 0.83585584],\n",
       "        [0.6458261 , 0.46785003, 0.35544762]],\n",
       "\n",
       "       [[1.2604403 , 0.7245729 , 1.4729478 ],\n",
       "        [1.6296195 , 1.1915321 , 2.0141234 ]],\n",
       "\n",
       "       [[0.28554264, 0.09845898, 0.19420289],\n",
       "        [1.7738057 , 1.1403537 , 1.0504711 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a, b) #(3*2*4)@(3*4*3) = (3*2*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYmcWP5fOMYj"
   },
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzrmujBNOMYm"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8OvUeISOMYp",
    "outputId": "ba7ecb53-eaf5-4661-e773-afa56b29fc21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=81, shape=(3, 2, 2, 4), dtype=float32, numpy=\n",
       "array([[[[0.8608031 , 0.36825335, 0.6292709 , 0.29536247],\n",
       "         [0.97098553, 0.32392263, 0.94630194, 0.12578309]],\n",
       "\n",
       "        [[0.30160272, 0.802788  , 0.9933553 , 0.65811276],\n",
       "         [0.73490727, 0.71324277, 0.8526089 , 0.49975812]]],\n",
       "\n",
       "\n",
       "       [[[0.22497427, 0.88556004, 0.17158055, 0.8955475 ],\n",
       "         [0.537349  , 0.11186874, 0.41308367, 0.2310288 ]],\n",
       "\n",
       "        [[0.6482841 , 0.96797216, 0.46565962, 0.47803152],\n",
       "         [0.34017062, 0.6268579 , 0.8093982 , 0.36721003]]],\n",
       "\n",
       "\n",
       "       [[[0.89483464, 0.01386333, 0.11346722, 0.6484195 ],\n",
       "         [0.32578707, 0.45205784, 0.6472889 , 0.64411163]],\n",
       "\n",
       "        [[0.30558026, 0.80952513, 0.18430853, 0.49258435],\n",
       "         [0.8959141 , 0.5489682 , 0.04652691, 0.10153389]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,2,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ap6ISJUTOMYs",
    "outputId": "85582bc7-53e7-4469-ba90-f8620c723c15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=89, shape=(3, 2, 4, 3), dtype=float32, numpy=\n",
       "array([[[[0.6665982 , 0.7778965 , 0.8313627 ],\n",
       "         [0.9081999 , 0.7577534 , 0.48216712],\n",
       "         [0.2566725 , 0.58552027, 0.08597457],\n",
       "         [0.6867578 , 0.504761  , 0.25473988]],\n",
       "\n",
       "        [[0.56002903, 0.9864079 , 0.9792932 ],\n",
       "         [0.8711171 , 0.14150643, 0.5778942 ],\n",
       "         [0.19876814, 0.5439323 , 0.54097223],\n",
       "         [0.07833743, 0.49583673, 0.35734534]]],\n",
       "\n",
       "\n",
       "       [[[0.06075251, 0.37482667, 0.2594881 ],\n",
       "         [0.4332422 , 0.946656  , 0.18483043],\n",
       "         [0.25615883, 0.53914785, 0.52498674],\n",
       "         [0.8872211 , 0.41392446, 0.87128425]],\n",
       "\n",
       "        [[0.6459657 , 0.12842119, 0.7841897 ],\n",
       "         [0.44894803, 0.27025878, 0.74508667],\n",
       "         [0.94663525, 0.89171374, 0.7588532 ],\n",
       "         [0.43372285, 0.57158184, 0.5778135 ]]],\n",
       "\n",
       "\n",
       "       [[[0.32961917, 0.08465743, 0.22805452],\n",
       "         [0.48332667, 0.74031126, 0.81933165],\n",
       "         [0.68329227, 0.11338997, 0.03645313],\n",
       "         [0.8860266 , 0.09634435, 0.30812788]],\n",
       "\n",
       "        [[0.86144316, 0.76657593, 0.15347731],\n",
       "         [0.42581928, 0.05240428, 0.3023641 ],\n",
       "         [0.05471265, 0.59455466, 0.48056102],\n",
       "         [0.5026469 , 0.14205563, 0.45313084]]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(3,2,4,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyzlUiPuOMYv",
    "outputId": "6398669a-01d9-4d1a-819f-4c1ea453d852"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=91, shape=(3, 2, 2, 3), dtype=float32, numpy=\n",
       "array([[[[1.2726165 , 1.4661993 , 1.0225412 ],\n",
       "         [1.2707158 , 1.6183491 , 1.0768259 ]],\n",
       "\n",
       "        [[1.117231  , 1.2777374 , 1.5318352 ],\n",
       "         [1.2415087 , 1.5374067 , 1.7716926 ]]],\n",
       "\n",
       "\n",
       "       [[[1.2358303 , 1.3858434 , 1.0924106 ],\n",
       "         [0.3919002 , 0.62565565, 0.57826763]],\n",
       "\n",
       "        [[1.5014815 , 1.0333256 , 1.8591813 ],\n",
       "         [1.4266374 , 1.144741  , 1.5602151 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9537034 , 0.16135518, 0.41936213],\n",
       "         [1.3388648 , 0.49769637, 0.666747  ]],\n",
       "\n",
       "        [[0.86563146, 0.4562289 , 0.6034476 ],\n",
       "         [1.0591215 , 0.7576408 , 0.3718579 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a,b) # (3*2*2*4)@(3*2*4*3)=(3*2*2*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhFWsCP1OMY0"
   },
   "source": [
    "## 1. 4 Transpose\n",
    "<pre>    - matrix transpose. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chFxqDYUOMY0",
    "outputId": "8f695cd4-a9fa-4e36-9775-6f13dad25ac1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=99, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.9537908 , 0.30431628],\n",
       "       [0.5151943 , 0.46175337],\n",
       "       [0.6791104 , 0.16136253]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcgW9_ctOMY5",
    "outputId": "7cee185b-054f-4300-d5b9-48b9665ce266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qoOVv8pOMY9",
    "outputId": "9e01e07a-026e-499e-ac90-781bd8edd78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=102, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.9537908 , 0.5151943 , 0.6791104 ],\n",
       "       [0.30431628, 0.46175337, 0.16136253]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwTCIpAQOMZA"
   },
   "source": [
    "<pre>We have a \"perm\" argument for transpose function, in that you can define youw own way to change rows and column positions. as shown below</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMyw2YIAOMZB",
    "outputId": "62093672-34a0-4f2d-a0db-3c7648ec3485"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(5), Dimension(4)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,5,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUquLpjJOMZG"
   },
   "outputs": [],
   "source": [
    "a_transpose = tf.transpose(a, perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4K7g_bAsOMZK",
    "outputId": "ef86f009-d814-4b24-cc5b-abee06aa420a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(5), Dimension(2), Dimension(4)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmDQktLGOMZO"
   },
   "source": [
    "<pre>My transposed matrix dim changed based on pem values( we transposed 1 and 2 axis only). you can check below example in that we chnaged all the axis</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD1ytjz0OMZP",
    "outputId": "b2acaecd-9ef3-4263-9eca-c8f91958cbfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(5), Dimension(4)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,5,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IagVMwNjOMZR"
   },
   "outputs": [],
   "source": [
    "a_transpose = tf.transpose(a, perm=[3, 2, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbcCTZuiOMZU",
    "outputId": "9d0c0432-706c-4b04-c0bb-fab83d6192ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(5), Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_galZ10JOMZX"
   },
   "source": [
    "## 1. 4 Element wise operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luaCDJ_8OMZY"
   },
   "source": [
    "### 1.4.1 Multiply Respective elements in two matrices\n",
    "Ex: \n",
    "<pre>\n",
    "A = [[1 2],\n",
    "     [3,4]]\n",
    "\n",
    "B = [[5,6],\n",
    "     [7,8]]\n",
    "\n",
    "we want A*B as \n",
    "[A[0][0]*B[0][0], A[0][1]*B[0][1]\n",
    "A[1][0]*B[1][0], A[1][1]*B[1][1]]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIOB8zyIOMZZ",
    "outputId": "3ec7c53e-9347-4950-8359-443895d507b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=128, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.9003049 , 0.80035365],\n",
       "       [0.47320974, 0.6631005 ],\n",
       "       [0.08535194, 0.87037086]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJxr1BFgOMZc",
    "outputId": "f1404940-d2f2-4f8e-d887-6863e9112890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=136, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.9724153 , 0.39724445],\n",
       "       [0.12542391, 0.02614367],\n",
       "       [0.9068719 , 0.50433683]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(3,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qszNHNK8OMZe",
    "outputId": "b2cf32a9-29dd-485b-e845-b8e1e788324a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=138, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.8754703 , 0.31793603],\n",
       "       [0.05935181, 0.01733588],\n",
       "       [0.07740328, 0.43896008]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLWk8lQkOMZg",
    "outputId": "7e4d4b95-e10e-48a2-e123-5ac3b5ada568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=140, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.8754703 , 0.31793603],\n",
       "       [0.05935181, 0.01733588],\n",
       "       [0.07740328, 0.43896008]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6KnJSQ9OMZi"
   },
   "source": [
    "<pre>You can do a*b or you can use tf.multiply</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8dLCOEaOMZj"
   },
   "source": [
    "## 1.5 Expanding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrSkSucPOMZj",
    "outputId": "66be7e9f-b2d9-4045-9b1f-a85e35d3cd1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ea9KHLbSOMZm"
   },
   "outputs": [],
   "source": [
    "a_add = tf.expand_dims(a, axis=1)#we are adding an additional axis at 1st dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfcxwikXOMZq",
    "outputId": "b735dccc-a254-47b9-9ee0-c0077237deb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(1), Dimension(2)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16tS1mknOMZu"
   },
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t28TsjlQOMZv"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q_MkdrgOMZw",
    "outputId": "dd3d6bd9-8bd4-441e-c51e-8a4d0432770c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3UzTFUFOMZ0"
   },
   "outputs": [],
   "source": [
    "a_add = tf.expand_dims(a, axis=2)#we are adding an additional axis at 2nd dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc4R99CxOMZ2",
    "outputId": "fbb6308d-198b-4437-af9d-1afb3d2c6b72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(1)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQayeY4wOMZ5"
   },
   "source": [
    "## 1.6 Squeezing dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVomMzI6OMZ6"
   },
   "source": [
    "<pre>\n",
    "Note that we can squeeze along with the axis with shape 1\n",
    "\n",
    "Ex: \n",
    "A.shape= [3,4,1] ==> we can squeez it on axis=2 will give [3,4]\n",
    "A.shape= [3,1,4] ==> we can squeez it on axis=1 will give [3,4]\n",
    "A.shape= [1,3,4] ==> we can squeez it on axis=0 will give [3,4]\n",
    "A.shape= [2,3,4] ==> we can't squeez it on any of the axis\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYqN12oiOMZ9",
    "outputId": "18ea673d-f869-4d7a-e369-4bcc976cde32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(1), Dimension(4)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,1,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-H6UcJfJOMaA"
   },
   "outputs": [],
   "source": [
    "a_squ = tf.squeeze(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTxBvofpOMaD",
    "outputId": "60a18069-76fd-405a-97e2-47962e7555f1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=167, shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0.3432275 , 0.91972435, 0.74566627, 0.9272661 ],\n",
       "       [0.453529  , 0.35869324, 0.6748843 , 0.85485756],\n",
       "       [0.17117417, 0.44973183, 0.8205396 , 0.27874458]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_squ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SArBwQROMaE"
   },
   "source": [
    "## 1.7 Reshaping of tensors\n",
    "\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/reshape'> check the documentation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEjdOLJROMaF",
    "outputId": "11764a1b-d324-457d-dd95-2e23e69169ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 4) (15, 4)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(5,3,4))\n",
    "# tf.reshape(tensor, [reshape dimensions]])\n",
    "b = tf.reshape(a, [a.shape[0]*a.shape[1],a.shape[2]])\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USHug53cOMaI"
   },
   "source": [
    "# 2. Call Backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYFub-clOMaJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Edk77ekZOMaM"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# if you observe the input shape its 3 dimensional vector\n",
    "# for each image we have a (28*28) vector\n",
    "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) \n",
    "Y_train = tf.keras.utils.to_categorical(y_train, 10) \n",
    "Y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zuUwtN0OMaO",
    "outputId": "da064def-dab6-4da9-a240-a4ec16f7dfdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6sg7WeVOMaP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_psPfAhOMaR"
   },
   "source": [
    "## 2.1 Writing custom call backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2zS015yOMaR"
   },
   "source": [
    "<pre>In Keras, Callback is a python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Up_jqqGfOMaS"
   },
   "source": [
    "<pre>\n",
    "<b>Writing Call Backs</b> - You can inherit from <b>`tf.keras.callbacks.Callback`</b>, Copied the code for callback class from tensorflow documentation and pased in below cell, you can check that code. It has many methods like batch/epoch_begin/end. so you can do manupulate the model parameters or print the required outputs using these methods. The `logs` dict contains the loss value, and all the metrics at the end of a batch or epoch\n",
    "\n",
    "</pre>\n",
    "> <a href='https://www.w3schools.com/python/python_inheritance.asp'> Do Read this Blog to understand how to inhert other classes </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cv88yZ_pOMaT"
   },
   "outputs": [],
   "source": [
    "class Callback(object):\n",
    "    \n",
    "    \"\"\"Abstract base class used to build new callbacks.\n",
    "      Attributes:\n",
    "          params: dict. Training parameters\n",
    "              (eg. verbosity, batch size, number of epochs...).\n",
    "          model: instance of `keras.models.Model`.\n",
    "              Reference of the model being trained.\n",
    "          validation_data: Deprecated. Do not use.\n",
    "      The `logs` dictionary that callback methods\n",
    "      take as argument will contain keys for quantities relevant to\n",
    "      the current batch or epoch.\n",
    "      Currently, the `.fit()` method of the `Model` class\n",
    "      will include the following quantities in the `logs` that\n",
    "      it passes to its callbacks:\n",
    "          on_epoch_end: logs include `acc` and `loss`, and\n",
    "          optionally include `val_loss`\n",
    "          (if validation is enabled in `fit`), and `val_acc`\n",
    "          (if validation and accuracy monitoring are enabled).\n",
    "          on_batch_begin: logs include `size`,\n",
    "          the number of samples in the current batch.\n",
    "          on_batch_end: logs include `loss`, and optionally `acc`\n",
    "            (if accuracy monitoring is enabled).\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.validation_data = None\n",
    "        self.model = None\n",
    "        # Whether this Callback should only run on the chief worker in a\n",
    "        # Multi-Worker setting.\n",
    "        # TODO(omalleyt): Make this attr public once solution is stable.\n",
    "        self._chief_worker_only = None\n",
    "\n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"Called at the start of an epoch.\n",
    "        Subclasses should override for any actions to run. This function should only\n",
    "        be called during TRAIN mode.\n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"Called at the end of an epoch.\n",
    "        Subclasses should override for any actions to run. This function should only\n",
    "        be called during TRAIN mode.\n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict, metric results for this training epoch, and for the\n",
    "              validation epoch if validation is performed. Validation result keys\n",
    "              are prefixed with `val_`.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a training batch in `fit` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "              number and the size of the batch.\n",
    "        \"\"\"\n",
    "        # For backwards compatibility.\n",
    "        self.on_batch_begin(batch, logs=logs)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a training batch in `fit` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "        # For backwards compatibility.\n",
    "        self.on_batch_end(batch, logs=logs)\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n",
    "        Also called at the beginning of a validation batch in the `fit`\n",
    "        methods, if validation data is provided.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "                  number and the size of the batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a batch in `evaluate` methods.\n",
    "        Also called at the end of a validation batch in the `fit`\n",
    "        methods, if validation data is provided.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a batch in `predict` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "                  number and the size of the batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a batch in `predict` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of training.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "                  but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"Called at the end of training.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "                  but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of evaluation or validation.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        \"\"\"Called at the end of evaluation or validation.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of prediction.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        \"\"\"Called at the end of prediction.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfZUPJ01OMah"
   },
   "outputs": [],
   "source": [
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['acc'].append(logs.get('acc'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_acc', -1) != -1:\n",
    "            self.history['val_acc'].append(logs.get('val_acc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzEyvZg-OMaj"
   },
   "source": [
    "> in the above function we have written logs={}, which means the logs is a dictionary and the keys present will the same values that gets printed while you train your model i.e model.fit()\n",
    "<img src='https://i.imgur.com/fAiHfe7.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ca3J3ySeOMak",
    "outputId": "7c7b689b-4e82-4f62-9cef-9882894ee2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1123 03:30:58.517693 13660 deprecation.py:323] From C:\\Users\\nsuguru\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 1.3811 - acc: 0.5008 - val_loss: 1.2494 - val_acc: 0.5757\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 1.1086 - acc: 0.6066 - val_loss: 0.9127 - val_acc: 0.6881\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.9752 - acc: 0.6628 - val_loss: 1.0289 - val_acc: 0.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a6ec5eaeb8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "history_own = LossHistory()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks=[history_own])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nzuF0OPOMam",
    "outputId": "4c4de85a-6095-4938-e92d-cc83993aad5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3810659975369772, 1.1086404606143634, 0.9752153354406357],\n",
       " 'acc': [0.5007833, 0.60656667, 0.66283333],\n",
       " 'val_loss': [1.2493917247295379, 0.9126582312107087, 1.028908223438263],\n",
       " 'val_acc': [0.5757, 0.6881, 0.6374]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_own.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "riBZE6ZrOMao"
   },
   "source": [
    "<pre><b>Writing the call back to terminate training if loss is 'NaN'</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMYmZMVeOMap"
   },
   "outputs": [],
   "source": [
    "class TerminateNaN(tf.keras.callbacks.Callback):\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vh4umPy9OMaq"
   },
   "source": [
    "## 2.2 Using tensorflow call backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qv9epZaHOMaq"
   },
   "source": [
    "<pre>There are some callbacks which are implemented in the Tensorflow\n",
    "\n",
    "<b>ModelCheckpoint</b> - Save the model after every epoch. You can check documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvIlgI2ROMas"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3-DSrb2OMau",
    "outputId": "0f12e82c-e169-4cd0-bf8a-c938384dfae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "59920/60000 [============================>.] - ETA: 0s - loss: 1.2527 - acc: 0.5629\n",
      "Epoch 00001: val_loss improved from inf to 1.16071, saving model to model_save/weights-01-0.6286.hdf5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'model_save/weights-01-0.6286.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-11e41ea34886>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m               loss='categorical_crossentropy',metrics=['accuracy'])\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m       \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    998\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \"\"\"\n\u001b[1;32m-> 1211\u001b[1;33m     \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format)\u001b[0m\n\u001b[0;32m    111\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    112\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 113\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'model_save/weights-01-0.6286.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "#file path, it saves the model in the 'model_save' folder and we are naming model with epoch number \n",
    "#and val acc to differtiate with other models\n",
    "#you have to create model_save folder before running the code.\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfAHPmifOMax"
   },
   "source": [
    "<pre>If you need 4th epoch model, you can load that model as below. It saves optimizer state as well. so noo need to recompile. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0AIY28BOMaz"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_save/weights-04-0.7914.hdf5')#change this with your name which you got in above output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJ7A1PJHOMa0",
    "outputId": "22cef2e7-19b9-452f-aaad-8ab3618451d1"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrHJBrPCOMa3"
   },
   "source": [
    "### 2.2.1 EarlyStopping:\n",
    "\n",
    "<pre>Stop training when a monitored quantity has stopped improving. You can check the documentatin <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FS1jubUuOMa3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BxU-droOMa6",
    "outputId": "4f77741c-cd29-4173-9d08-5ab8b7ad6a48"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "#you can monitor any quantity (here i am monitoring val_loss), you can give any number for patience based on your need. \n",
    "#i am terminating training if my validation loss incresing at once than previous loss. so maintained 1. you can give min delta\n",
    "#an absolute change of less than min_delta, will count as no improvement. i maintained 0.35 because i don't want to run \n",
    "#so many epoch to see termination\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.35, patience=1, verbose=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test),batch_size=16,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05WyP1W2OMa9"
   },
   "source": [
    "<pre>It stopped at 2nd epoch only. You can use this early stopping to get best model than overfitted model</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjQJADh8OMa-"
   },
   "source": [
    "### 2.2.2 LearningRateScheduler:\n",
    "<pre>You can schedule learning rate for every epoch. You can decrease or increase the learning rate based on epoch number. </pre> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "er-L_eZIOMa_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YONlCwyOMbA"
   },
   "outputs": [],
   "source": [
    "def changeLearningRate(epoch):\n",
    "    initial_learningrate=0.1\n",
    "    changed = initial_learningrate*(1-0.1)**epoch\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hS18HNhtOMbC"
   },
   "outputs": [],
   "source": [
    "changed_lr = []\n",
    "for i in range(1,50):\n",
    "    changed_lr.append(changeLearningRate(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7JjoQ2aOMbE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSdopgjfOMbG",
    "outputId": "a21ca1de-08c0-4e61-b0af-b0c89075e0ee"
   },
   "outputs": [],
   "source": [
    "plt.plot(changed_lr)\n",
    "plt.ylabel('learning_rate')\n",
    "plt.xlabel('epoch number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSvB3InnOMbH"
   },
   "source": [
    "<pre>If you check above figure, learning rate is decreasing if my epoch number is increasing. I am using same function to schedule our learning rate based on epoch number. You can write your own function or you can write custom call back to decrease the learning rate based on val_loss/acc. \n",
    "In the above function, i have implemented exponential decay with decay rate 0.1, you can check that <a href=\"https://mathbitsnotebook.com/Algebra2/Exponential/EXGrowthDecay.html\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTZCQXQ_OMbH",
    "outputId": "fc89d5ee-2db1-4376-bade-053be24b01de"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[lrschedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVm_fKElOMbK"
   },
   "source": [
    "### 2.2.3 ReduceLROnPlateau\n",
    "<pre>It is similar to EarlyStopping, you can reduce your Learning rate by some factor if my val_loss/acc is not improving. You can check the documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\">here</a></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V35jamIuOMbL"
   },
   "source": [
    "<pre>There are many pre built call backs are available in Tensorflow, you can check those in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\">this</a> link.\n",
    "\n",
    "You can give as many callbacks you want while training the model as given below.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ts8yx-dwOMbO",
    "outputId": "a841d5e3-0b9f-4916-b35e-8a98337b8c79"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "#create a call back list\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=0.1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.25, patience=1, verbose=1)\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "# here we are creating a list with all the callbacks we want\n",
    "callback_list = [lrschedule, earlystop, checkpoint]\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=callback_list)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0fjRvsmIOMYG",
    "vhFWsCP1OMY0",
    "_galZ10JOMZX",
    "luaCDJ_8OMZY",
    "z8dLCOEaOMZj",
    "OQayeY4wOMZ5",
    "_SArBwQROMaE"
   ],
   "name": "Call_Backs_Reference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
