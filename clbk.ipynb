{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQDRNrY2NCXf"
   },
   "source": [
    "<pre>\n",
    "1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>\n",
    "\n",
    "2. Code the model to classify data like below image\n",
    "\n",
    "<img src='https://i.imgur.com/33ptOFy.png'>\n",
    "\n",
    "3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n",
    "\n",
    "4. Save your model at every epoch if your validation accuracy is improved from previous epoch. \n",
    "\n",
    "5. you have to decay learning based on below conditions \n",
    "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
    "               learning rate by 10%. \n",
    "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
    "        \n",
    "6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n",
    "\n",
    "7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
    "\n",
    "8. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
    "\n",
    "9. use cross entropy as loss function\n",
    "\n",
    "10. Try the architecture params as given below. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w41Y3TFENCXk"
   },
   "source": [
    "<pre>\n",
    "<b>Model-1</b>\n",
    "<pre>\n",
    "1. Use tanh as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use RandomUniform(0,1) as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>\n",
    "</pre>\n",
    "<pre>\n",
    "<b>Model-2</b>\n",
    "<pre>\n",
    "1. Use relu as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use RandomUniform(0,1) as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>\n",
    "</pre>\n",
    "<pre>\n",
    "<b>Model-3</b>\n",
    "<pre>\n",
    "1. Use relu as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use he_uniform() as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>\n",
    "</pre>\n",
    "<pre>\n",
    "<b>Model-4</b>\n",
    "<pre>\n",
    "1. Try with any values to get better accuracy/f1 score.  \n",
    "</pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2)\n",
      "(5000, 2)\n",
      "(15000,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\nsuguru\\\\Desktop\\\\data.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data.loc[:,'f1':'f2']\n",
    "Y=data.loc[:,'label']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, stratify=Y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'acc': [],'val_loss': [],'val_acc': []}\n",
    "        print('train_begin')\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print('\\n','epoch_end')\n",
    "        # predict probabilities for test set\n",
    "        yhat_probs = model.predict(X_test, verbose=0)\n",
    "        # predict crisp classes for test set\n",
    "        #yhat_classes = model.predict_proba(X_test, verbose=0)\n",
    "        # reduce to 1d array\n",
    "        yhat_probs = yhat_probs[:, 0]\n",
    "        #yhat_classes = yhat_classes[:, 0]\n",
    "        #f1 = f1_score(Y_test, yhat_classes)\n",
    "        #print('F1 score: %f' % f1)\n",
    "        auc = roc_auc_score(Y_test, yhat_probs)\n",
    "        print('ROC AUC: %f' % auc)\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['acc'].append(logs.get('acc'))\n",
    "        #self.history['auc'].append(logs.get('auc'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_acc', -1) != -1:\n",
    "            self.history['val_acc'].append(logs.get('val_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 5000 samples\n",
      "train_begin\n",
      "Epoch 1/100\n",
      " 1000/15000 [=>............................] - ETA: 1s - loss: 5.6971 - acc: 0.4780\n",
      " epoch_end\n",
      "ROC AUC: 0.480002\n",
      "15000/15000 [==============================] - 0s 18us/sample - loss: 4.9778 - acc: 0.5013 - val_loss: 4.6114 - val_acc: 0.4816\n",
      "Epoch 2/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 4.7474 - acc: 0.4970\n",
      " epoch_end\n",
      "ROC AUC: 0.478902\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 4.4374 - acc: 0.4950 - val_loss: 4.1854 - val_acc: 0.4798\n",
      "Epoch 3/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 4.2824 - acc: 0.4860\n",
      " epoch_end\n",
      "ROC AUC: 0.519658\n",
      "15000/15000 [==============================] - 0s 6us/sample - loss: 3.9386 - acc: 0.4923 - val_loss: 3.6516 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 4.0293 - acc: 0.4840\n",
      " epoch_end\n",
      "ROC AUC: 0.520936\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 3.6208 - acc: 0.5000 - val_loss: 3.2469 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 3.1689 - acc: 0.5010\n",
      " epoch_end\n",
      "ROC AUC: 0.533506\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 3.0325 - acc: 0.5000 - val_loss: 2.5341 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 2.6597 - acc: 0.4970\n",
      " epoch_end\n",
      "ROC AUC: 0.545950\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 2.0841 - acc: 0.5166 - val_loss: 1.4913 - val_acc: 0.5448\n",
      "Epoch 7/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 1.4790 - acc: 0.5310\n",
      " epoch_end\n",
      "ROC AUC: 0.535217\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 1.0858 - acc: 0.5445 - val_loss: 0.8872 - val_acc: 0.5350\n",
      "Epoch 8/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.8359 - acc: 0.5340\n",
      " epoch_end\n",
      "ROC AUC: 0.526064\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.8201 - acc: 0.5334 - val_loss: 0.7680 - val_acc: 0.5262\n",
      "Epoch 9/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.7489 - acc: 0.5250\n",
      " epoch_end\n",
      "ROC AUC: 0.517905\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.7430 - acc: 0.5221 - val_loss: 0.7126 - val_acc: 0.5174\n",
      "Epoch 10/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6956 - acc: 0.5370\n",
      " epoch_end\n",
      "ROC AUC: 0.513446\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.7122 - acc: 0.5163 - val_loss: 0.6956 - val_acc: 0.5134\n",
      "Epoch 11/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6913 - acc: 0.5040\n",
      " epoch_end\n",
      "ROC AUC: 0.513010\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.7055 - acc: 0.5131 - val_loss: 0.6942 - val_acc: 0.5130\n",
      "Epoch 12/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6820 - acc: 0.5330\n",
      " epoch_end\n",
      "ROC AUC: 0.512204\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.7007 - acc: 0.5110 - val_loss: 0.6932 - val_acc: 0.5120\n",
      "Epoch 13/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6854 - acc: 0.5110\n",
      " epoch_end\n",
      "ROC AUC: 0.509400\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6960 - acc: 0.5097 - val_loss: 0.6936 - val_acc: 0.5094\n",
      "Epoch 14/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6850 - acc: 0.5150\n",
      " epoch_end\n",
      "ROC AUC: 0.508597\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6932 - acc: 0.5082 - val_loss: 0.6942 - val_acc: 0.5084\n",
      "Epoch 15/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6897 - acc: 0.5070\n",
      " epoch_end\n",
      "ROC AUC: 0.508199\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6925 - acc: 0.5073 - val_loss: 0.6943 - val_acc: 0.5078\n",
      "Epoch 16/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6906 - acc: 0.5160\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6921 - acc: 0.5067 - val_loss: 0.6934 - val_acc: 0.5076\n",
      "Epoch 17/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6930 - acc: 0.4740\n",
      " epoch_end\n",
      "ROC AUC: 0.507000\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6912 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.5070\n",
      "Epoch 18/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6911 - acc: 0.5140\n",
      " epoch_end\n",
      "ROC AUC: 0.506401\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6909 - acc: 0.5058 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 19/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6904 - acc: 0.5010\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6908 - acc: 0.5055 - val_loss: 0.6934 - val_acc: 0.5062\n",
      "Epoch 20/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6911 - acc: 0.4600\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 21/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6881 - acc: 0.5160\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 22/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6980 - acc: 0.5090\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6935 - val_acc: 0.5060\n",
      "Epoch 23/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6903 - acc: 0.5100\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5054 - val_loss: 0.6935 - val_acc: 0.5060\n",
      "Epoch 24/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6911 - acc: 0.5090\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 25/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6898 - acc: 0.5120\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 26/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6916 - acc: 0.5280\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5054 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 27/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6885 - acc: 0.5280\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 28/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6883 - acc: 0.5240\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5054 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 29/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6930 - acc: 0.5010\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 30/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6900 - acc: 0.5410\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 31/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6945 - acc: 0.4870\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6907 - acc: 0.5054 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 32/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6914 - acc: 0.5160\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6907 - acc: 0.5320\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6907 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 34/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6918 - acc: 0.4580\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 35/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6924 - acc: 0.5140\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 36/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6936 - acc: 0.5310\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 37/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6882 - acc: 0.5040\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 38/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6860 - acc: 0.5180\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 39/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6921 - acc: 0.4930\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 40/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6875 - acc: 0.5280\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 41/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6874 - acc: 0.4980\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 42/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6914 - acc: 0.5000\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 43/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6903 - acc: 0.5110\n",
      " epoch_end\n",
      "ROC AUC: 0.505999\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5055 - val_loss: 0.6934 - val_acc: 0.5060\n",
      "Epoch 44/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6883 - acc: 0.5250\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 45/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6898 - acc: 0.4760\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 46/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6900 - acc: 0.5380\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5055 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 47/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6938 - acc: 0.5330\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5053 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 48/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6928 - acc: 0.5320\n",
      " epoch_end\n",
      "ROC AUC: 0.506198\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 49/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6920 - acc: 0.4950\n",
      " epoch_end\n",
      "ROC AUC: 0.506201\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 50/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6909 - acc: 0.5140\n",
      " epoch_end\n",
      "ROC AUC: 0.506001\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5056 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 51/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6910 - acc: 0.5110\n",
      " epoch_end\n",
      "ROC AUC: 0.506201\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 52/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6930 - acc: 0.5150\n",
      " epoch_end\n",
      "ROC AUC: 0.506401\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5062\n",
      "Epoch 53/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6943 - acc: 0.4940\n",
      " epoch_end\n",
      "ROC AUC: 0.506201\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5055 - val_loss: 0.6933 - val_acc: 0.5060\n",
      "Epoch 54/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6938 - acc: 0.5060\n",
      " epoch_end\n",
      "ROC AUC: 0.506600\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5062\n",
      "Epoch 55/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6902 - acc: 0.5070\n",
      " epoch_end\n",
      "ROC AUC: 0.506600\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5056 - val_loss: 0.6933 - val_acc: 0.5062\n",
      "Epoch 56/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6878 - acc: 0.5250\n",
      " epoch_end\n",
      "ROC AUC: 0.506600\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5056 - val_loss: 0.6933 - val_acc: 0.5062\n",
      "Epoch 57/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6918 - acc: 0.4820\n",
      " epoch_end\n",
      "ROC AUC: 0.506800\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5062\n",
      "Epoch 58/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6918 - acc: 0.5110\n",
      " epoch_end\n",
      "ROC AUC: 0.506800\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5055 - val_loss: 0.6933 - val_acc: 0.5064\n",
      "Epoch 59/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6894 - acc: 0.4880\n",
      " epoch_end\n",
      "ROC AUC: 0.506800\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5055 - val_loss: 0.6932 - val_acc: 0.5064\n",
      "Epoch 60/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6901 - acc: 0.5130\n",
      " epoch_end\n",
      "ROC AUC: 0.506800\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5057 - val_loss: 0.6933 - val_acc: 0.5064\n",
      "Epoch 61/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6910 - acc: 0.5320\n",
      " epoch_end\n",
      "ROC AUC: 0.506800\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5055 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 62/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6931 - acc: 0.4820\n",
      " epoch_end\n",
      "ROC AUC: 0.507199\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5057 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 63/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6884 - acc: 0.5000\n",
      " epoch_end\n",
      "ROC AUC: 0.507199\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5058 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 64/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6895 - acc: 0.5130\n",
      " epoch_end\n",
      "ROC AUC: 0.507199\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6906 - acc: 0.5059 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 65/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6885 - acc: 0.5250\n",
      " epoch_end\n",
      "ROC AUC: 0.507399\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5057 - val_loss: 0.6932 - val_acc: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6918 - acc: 0.5050\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5059 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 67/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6908 - acc: 0.5310\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5061 - val_loss: 0.6932 - val_acc: 0.5072\n",
      "Epoch 68/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6934 - acc: 0.5290\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6906 - acc: 0.5059 - val_loss: 0.6932 - val_acc: 0.5072\n",
      "Epoch 69/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6898 - acc: 0.5180\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5061 - val_loss: 0.6931 - val_acc: 0.5076\n",
      "Epoch 70/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6906 - acc: 0.5080\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.5076\n",
      "Epoch 71/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6911 - acc: 0.4690\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6905 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.5076\n",
      "Epoch 72/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6896 - acc: 0.4990\n",
      " epoch_end\n",
      "ROC AUC: 0.507599\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5066 - val_loss: 0.6931 - val_acc: 0.5076\n",
      "Epoch 73/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6889 - acc: 0.5060\n",
      " epoch_end\n",
      "ROC AUC: 0.507799\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.5076\n",
      "Epoch 74/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6895 - acc: 0.5020\n",
      " epoch_end\n",
      "ROC AUC: 0.507799\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.5078\n",
      "Epoch 75/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6870 - acc: 0.5250\n",
      " epoch_end\n",
      "ROC AUC: 0.507799\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5068 - val_loss: 0.6930 - val_acc: 0.5078\n",
      "Epoch 76/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6924 - acc: 0.5150\n",
      " epoch_end\n",
      "ROC AUC: 0.508198\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5069 - val_loss: 0.6929 - val_acc: 0.5078\n",
      "Epoch 77/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6887 - acc: 0.4960\n",
      " epoch_end\n",
      "ROC AUC: 0.508398\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6905 - acc: 0.5074 - val_loss: 0.6929 - val_acc: 0.5078\n",
      "Epoch 78/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6897 - acc: 0.5100\n",
      " epoch_end\n",
      "ROC AUC: 0.508598\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6904 - acc: 0.5071 - val_loss: 0.6929 - val_acc: 0.5082\n",
      "Epoch 79/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6875 - acc: 0.4980\n",
      " epoch_end\n",
      "ROC AUC: 0.508598\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6904 - acc: 0.5074 - val_loss: 0.6928 - val_acc: 0.5086\n",
      "Epoch 80/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6858 - acc: 0.5180\n",
      " epoch_end\n",
      "ROC AUC: 0.509001\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6904 - acc: 0.5075 - val_loss: 0.6927 - val_acc: 0.5086\n",
      "Epoch 81/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6895 - acc: 0.4940\n",
      " epoch_end\n",
      "ROC AUC: 0.509200\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6903 - acc: 0.5079 - val_loss: 0.6927 - val_acc: 0.5092\n",
      "Epoch 82/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6893 - acc: 0.5240\n",
      " epoch_end\n",
      "ROC AUC: 0.509400\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6903 - acc: 0.5081 - val_loss: 0.6926 - val_acc: 0.5090\n",
      "Epoch 83/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6911 - acc: 0.5270\n",
      " epoch_end\n",
      "ROC AUC: 0.509603\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6903 - acc: 0.5079 - val_loss: 0.6926 - val_acc: 0.5092\n",
      "Epoch 84/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6904 - acc: 0.5080\n",
      " epoch_end\n",
      "ROC AUC: 0.510402\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6902 - acc: 0.5081 - val_loss: 0.6925 - val_acc: 0.5096\n",
      "Epoch 85/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6945 - acc: 0.5160\n",
      " epoch_end\n",
      "ROC AUC: 0.511001\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6902 - acc: 0.5083 - val_loss: 0.6924 - val_acc: 0.5100\n",
      "Epoch 86/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6894 - acc: 0.5310\n",
      " epoch_end\n",
      "ROC AUC: 0.511600\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6901 - acc: 0.5089 - val_loss: 0.6923 - val_acc: 0.5108\n",
      "Epoch 87/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6906 - acc: 0.5230\n",
      " epoch_end\n",
      "ROC AUC: 0.512403\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6901 - acc: 0.5092 - val_loss: 0.6922 - val_acc: 0.5116\n",
      "Epoch 88/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6908 - acc: 0.5070\n",
      " epoch_end\n",
      "ROC AUC: 0.512807\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6900 - acc: 0.5101 - val_loss: 0.6920 - val_acc: 0.5124\n",
      "Epoch 89/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6924 - acc: 0.5270\n",
      " epoch_end\n",
      "ROC AUC: 0.513605\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6899 - acc: 0.5111 - val_loss: 0.6918 - val_acc: 0.5128\n",
      "Epoch 90/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6909 - acc: 0.5090\n",
      " epoch_end\n",
      "ROC AUC: 0.513427\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6897 - acc: 0.5121 - val_loss: 0.6914 - val_acc: 0.5136\n",
      "Epoch 91/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6909 - acc: 0.4850\n",
      " epoch_end\n",
      "ROC AUC: 0.514428\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6895 - acc: 0.5127 - val_loss: 0.6911 - val_acc: 0.5140\n",
      "Epoch 92/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6875 - acc: 0.5300\n",
      " epoch_end\n",
      "ROC AUC: 0.516252\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6892 - acc: 0.5145 - val_loss: 0.6907 - val_acc: 0.5154\n",
      "Epoch 93/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6941 - acc: 0.5140\n",
      " epoch_end\n",
      "ROC AUC: 0.516893\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6888 - acc: 0.5167 - val_loss: 0.6902 - val_acc: 0.5164\n",
      "Epoch 94/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6859 - acc: 0.5300\n",
      " epoch_end\n",
      "ROC AUC: 0.519318\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6884 - acc: 0.5178 - val_loss: 0.6897 - val_acc: 0.5184\n",
      "Epoch 95/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6891 - acc: 0.5020\n",
      " epoch_end\n",
      "ROC AUC: 0.520335\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6880 - acc: 0.5202 - val_loss: 0.6893 - val_acc: 0.5194\n",
      "Epoch 96/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6930 - acc: 0.5110\n",
      " epoch_end\n",
      "ROC AUC: 0.521952\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6876 - acc: 0.5211 - val_loss: 0.6890 - val_acc: 0.5210\n",
      "Epoch 97/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6874 - acc: 0.5160\n",
      " epoch_end\n",
      "ROC AUC: 0.523732\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6872 - acc: 0.5230 - val_loss: 0.6886 - val_acc: 0.5230\n",
      "Epoch 98/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6923 - acc: 0.5220\n",
      " epoch_end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.525352\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6870 - acc: 0.5240 - val_loss: 0.6884 - val_acc: 0.5244\n",
      "Epoch 99/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6990 - acc: 0.5360\n",
      " epoch_end\n",
      "ROC AUC: 0.526395\n",
      "15000/15000 [==============================] - 0s 4us/sample - loss: 0.6867 - acc: 0.5253 - val_loss: 0.6882 - val_acc: 0.5264\n",
      "Epoch 100/100\n",
      " 1000/15000 [=>............................] - ETA: 0s - loss: 0.6810 - acc: 0.5410\n",
      " epoch_end\n",
      "ROC AUC: 0.526416\n",
      "15000/15000 [==============================] - 0s 5us/sample - loss: 0.6866 - acc: 0.5252 - val_loss: 0.6881 - val_acc: 0.5260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27a6fa57710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(2,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1,seed=20))(input_layer)\n",
    "layer2 = Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1,seed=30))(layer1)\n",
    "layer3 = Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1,seed=40))(layer2)\n",
    "layer4 = Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1,seed=50))(layer3)\n",
    "layer5 = Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1,seed=60))(layer4)\n",
    "\n",
    "#output layer\n",
    "output = Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=70))(layer5)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "history_own = LossHistory()\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=100, validation_data=(X_test,Y_test), batch_size=1000, callbacks=[history_own])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [7.6666240976817575,\n",
       "  7.6666239339913895,\n",
       "  7.666623891289555,\n",
       "  7.666623898406527,\n",
       "  7.666623912640472],\n",
       " 'acc': [0.5, 0.5, 0.5, 0.5, 0.5],\n",
       " 'val_loss': [7.6666239969658125,\n",
       "  7.6666239536169805,\n",
       "  7.6666239102681475,\n",
       "  7.6666239536169805,\n",
       "  7.666623866919315],\n",
       " 'val_acc': [0.5, 0.5, 0.5, 0.5, 0.5]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_own.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "W1130 12:56:16.314110 10824 deprecation_wrapper.py:119] From C:\\Users\\nsuguru\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1130 12:56:16.315103 10824 deprecation_wrapper.py:119] From C:\\Users\\nsuguru\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-80af6dbea865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tanh'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    160\u001b[0m                         \u001b[0mbatch_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                         name=layer.name + '_input')\n\u001b[0m\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# This will build the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[0;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                              input_tensor=tensor)\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[0;32m     85\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                                          name=self.name)\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   2138\u001b[0m   \"\"\"\n\u001b[0;32m   2139\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2140\u001b[1;33m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[0;32m   2141\u001b[0m                        \"eager execution.\")\n\u001b[0;32m   2142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=2, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "history_own = LossHistory()\n",
    "#optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=200, validation_data=(X_test,Y_test), batch_size=1000, callbacks=[history_own])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Call_Backs_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
